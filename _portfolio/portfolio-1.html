---
title: "1. Image segmentation as graph clustering with coupled oscillators"
excerpt: "<img src='/images/img_seg_model.png' width='550' height='400'/> &nbsp;&nbsp;&nbsp;&nbsp; <img src='/images/cartoonization.png' width='350' height='200'/> <br/>  Inspired by neuroscience and the retina, we pioneered a computer vision model that performs image segmentation by grouping together nearby image regions with similar features in phase space, resulting in an image with smoothed texture inside segments while maintaining crisp edges at segment boundaries - a 'cartoonization' of the image. The model recasts image segmentation as a graph clustering problem, both leveraging and contributing to a body of literature. Additionally, it simulates phase relaxation in a dynamical system of coupled Kuramoto oscillators with the strength of interaction defined by the Topographic Modularity graph between regions in the image. We demonstrate that this method outperforms other graph theoretic network construction methods as well as spectral Eigen-based methods for community detection by evaluating performance on the Berkeley Image Segmentation Dataset (BSDS). Such an image segmentation / contextual grouping computation could be performed in the first stage of visual processing, the retina."
collection: portfolio
---

 <p style="text-align: center; font-size:11pt"><strong>Expertise Demonstrated:</strong> Stuff </p>

Synchrony in periodic retinal spike trains may convey contextual information about the visual input, which is extracted by computations in the retinal network. To explore this hypothesis, we construct a computational model for image segmentation consisting of Kuramoto coupled oscillators whose phases model the timing of individual retinal spikes. Phase couplings between oscillators are shaped by the stimulus structure, causing cells to synchronize when the local contrast in their receptive fields is similar. In essence, phase relaxation in the oscillator network solves a graph clustering problem with the graph representing feature similarity between different points in the image. The resulting spike trains would multiplex these two information streams, local contrast in individual spike rates, and image segments in sets of neurons that fire nearly synchronously, into spike trains of Retinal Ganglion cells. <br/> 
<p align="center" width="100%">
  <img src='/images/img_seg_model_full.png'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 1</strong> Image Segmentation Model: (a) Input image with superimposed retinal receptive fields (dashed cyan circles). (b) Network of retinal neurons. The neural firing rates $r_i$ represent local contrast in the receptive fields. The phase interactions $K_{ij}$ are displayed by the links between neurons. Line thickness represents the strength of the interaction which is set by the similarity of local features. Recurrent propagation and relaxation in the network produces the phase structure $\phi_i$ of the periodic spike trains. (c) Resulting spike trains. Information about local features is represented in firing rates and segmentation is represented in phase structure. </p>
</p>

Qualitatively, the phase structure after relaxation results in the "cartoonization" of the original image, smoothing away texture within segments while keeping boundaries at the edges of objects crisp. This provides a basic image segmentation that could feasibly occur within the retinal network and using the signals that are available to the retinal neurons, which is packaged into a format (synchronous spiking) that downstream neurons are known to be sensitive to and sent to the visual cortex for further processing. <br/>  
<p align="center" width="100%">
  <img src='/images/cartoonization.png' align='center' width='600' height='200'/> 
  <p style="text-align: center; font-size:10pt"><strong>fig. 2</strong> Two examples of cartoonization: Original images on left and resulting phase of network computation on right. </p>
</p>

This work makes two significant technical contributions in posing image segmentation as a graph clustering problem. First, we introduce the 2D Topographic Modularity method to construct the phase interaction network as an extension to Newman's modularity method for detecting communities in graph structures, comparing it to other methods (i.e., Association - AA, Laplacian - GL, Modularity - M). Second, we improve upon spectral (Eigenvector based) methods for finding clusters in graphs by simulating a system of Kuramoto coupled oscillators. Each contribution improves image segmentation performance over existing methods. <br/> 
<p align="center" width="100%">
  <img src='/images/Modularity_0D_1D_2D.png' align='center' width='700' height='550'/> 
  <p style="text-align: center; font-size:10pt"><strong>fig. 3</strong> Modularity null models: In the null model of Newman’s modularity (panel a) the average weight between nodes i and j is proportional to the product of their node degrees $(D_i · D_j)$. The topographic modularity’s null model (panels b & c) additionally includes a distance-dependent factor, $R_{ij}$, which is the average edge weight between all node pairs in the graph separated by the same distance that separates nodes i and j. Panel b illustrates $R_{ij}$ for a schematized 1D graph, shown with edges colored based on distance between the nodes they connect. Inset plot shows geometric factor in the topographic null model. Each term in $R^{(1D)}_{ij}$ is an off-diagonal sum in the adjacency matrix. Panel c shows the mask associated with a single geometric distance in a 2D image. Here R^{(2D)} at 1 pixel separation has the complex structure in the Adjacency matrix for even the simple binary image shown in the inset. </p>
</p>

To assess the model's performance and compare it to other methods, we leverage the <a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/">Berkeley Image Segmentation Data Set (BSDS)</a>, which provides images, human drawn segmentations and benchmarking protocol. We use the performance evaluation pipeline shown below to compute Precision, Recall and F-measure metrics between human annotations and segment boundaries discovered by the algorithm. <br/> 
<p align="center" width="100%">
  <img src='/images/SegAssessPipeline.png' align='center' width='700' height='500'/> 
  <p style="text-align: center; font-size:10pt"><strong>fig. 4</strong> Performance and benchmarking: Input image patch and associated human drawn ground truth boundaries (gT) provided by BSDS are displayed in the green box. The operations performed by model are displayed in the blue box. Other steps of model evaluation are illustrated in the remainder. (a) Filtering the raw image patch with a Gaussian kernel ($\sigma$ = 1). (b) Phase relaxation in the network produces a phase map. (c 1) Spatial gradient operation ($\delta$/$\delta$r) and normalization resulting in probabilistic boundary map (pb $\in$ [0, 1]). (d) Thresholding pb map at several values yielded binary boundary (bb) maps. (e) Match set was computed for each bb-gT pair at different distance tolerances, dt. (f) Precision, recall and F-measure were computed by ratios of boundary pixel sets. (c 2,3) To assess the performance of network models relative to baselines, we repeated steps (c) - (f) on Gaussian RF and image pixels independent sensors models, comparing F-measures by subtraction. </p>
</p>

The F-measure metric, shown below, computes the geometric mean between Precision (how many boundary pixels declared by the algorithm are correct) and Recall (how many boundary pixels declared by human annotators are found by the algorithm). It demonstrates clear and statistically significant improvement in boundary detection provided by the 2D Topographic Modularity method (TM-2D) with Kuramoto relaxation over other methods as well as some improvement with the 1D Topographic Modularity method. The algorithm made those gains by improving Precision without degrading Recall, decreasing the strength of spurrious boundaries (texture within segments) while keeping strong the edges at segment boundaries. <br/> 
<p align="center" width="100%">
  <img src='/images/Fmax_img_seg.jpg' align='center' width='750' height='500'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 5</strong> $\Delta$F-measure model comparison: Violin plots show $\Delta F_G$ distribution with moments of $\Delta$Precision, $\Delta$Recall and $\Delta$F-measure distributions across 500 image patches in red, blue and green, respectively. $\Delta$F relative to Gaussian RF Independent Sensors model. Optimal hyper-parameters(rM ,ks), statistical significance, p-values and distribution moments indicated above each method. Performance of ISO, TM-1D and TM-2D models relative to Gauss RF are statistically significant, as determined by Mann-Whitney U (aka rank-sum) test. </p>
</p>

To provide intuition, we show some example probabilistic boundary images found by different versions of the model. Note that edges found by the Topographic Modularity (TM) model are sharp in locations coinciding with ground truth boundaries (GT) and very dark where there are no boundaries in the ground truth. <br/> 
<p align="center" width="100%">
  <img src='/images/pb_results_img_seg.png' align='center' width='750' height='1000'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 6</strong> Representative image patches: Each row shows one example image patch ordered by change in F-measure between Gaussian RF independent sensors baseline and TM models (indicated on left). Columns show image pixels, gT boundaries and pb maps obtained from raw pixels, Gaussian RF and 5 network models. Mean F-measure value across all gT’s noted below each pane is red if $\Delta F_G \gt 0$. </p>
</p>




Find the full publication <a href="https://chris-warner-ii.github.io/publication/2020-paper-2">here</a>,

and the code repo <a href="https://github.com/chris-warner-II/Image_Segmentation_Codebase">here</a>.
