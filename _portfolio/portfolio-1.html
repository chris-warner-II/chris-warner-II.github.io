---
title: "1. Coupled oscillator model for image segmentation"
excerpt: "<img src='/images/img_seg_model.png'> <img src='/images/cartoonization.png'> <br/> Inspired by neuroscience and the retina, we pioneered a computer vision model that performs image segmentation by grouping together nearby image regions with similar features in phase space, resulting in an image with smoothed texture inside segments and yet with crisp boundaries across segments maintained - a "cartoonization" of the image. The model recasts image segmentation as a graph clustering problem, simulating phase relaxation in a system of coupled Kuramoto oscillators with the strength of interaction defined by the Topographic Modularity between regions in the image. We demonstrate that this method outperforms other graph theoretic network construction methods as well as spectral Eigen-based methods for community detection by evaluating performance on the Berkeley Image Segmentation Dataset (BSDS)."
collection: portfolio
---

Synchrony in periodic retinal spike trains may convey contextual information about the visual input, which is extracted by computations in the retinal network. To explore this hypothesis, we construct a computational model for image segmentation consisting of a Kuramoto model of coupled oscillators whose phases model the timing of individual retinal spikes. Phase couplings between oscillators are shaped by the stimulus structure, causing cells to synchronize when the local contrast in their receptive fields is similar. In essence, phase relaxation in the oscillator network solves a graph clustering problem with the graph representing feature similarity between different points in the image. The resulting spike trains can multiplex these two types of information, local contrast in individual spike rates, and image segments in sets of neurons that fire nearly synchronously. <br/> 
<p align="center" width="100%">
  <img src='/images/img_seg_model_full.png'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 1</strong> Image Segmentation Model: (a) Input image with superimposed retinal receptive fields (dashed cyan circles). (b) Network of retinal neurons. The neural firing rates ri represent local contrast in the receptive fields. The phase interactions Kij are displayed by the links between neurons. Line thickness represents the strength of the interaction which is set by the similarity of local features. Recurrent propagation in the network produces the phase structure φi of the periodic spike trains. (c) Resulting spike trains. Information about local features is represented in firing rates and segmentation is represented in phase structure. </p>
</p>

Qualitatively, the phase map after relaxation results in the "cartoonization" of the original image, smoothing away texture within segments while keeping boundaries at the edges of objects crisp. This provides a rudimentary image segmentation that could feasibly occur within the hardware of and using what signals are available to the retina.  
<p align="center" width="100%">
<img src='/images/cartoonization.png' align='center' width='550' height='250'/> 
<p style="text-align: center; font-size:10pt"><strong>fig. 2</strong> Two examples of cartoonization: Original images on left and resulting phase of network computation on right. </p>
</p>

This work makes two significant technical contributions by posing image segmentation as a graph clustering problem. First, we introduce the 2D Topographic Modularity method to construct the phase interaction network as an extension to Newman's modularity method for detecting communities in graph structures. Second, we improve upon spectral (Eigenvector based) methods for finding clusters in graphs by simulating a system of Kuramoto coupled oscillators. Each contribution improves image segmentation performance over the alternative.
<p align="center" width="100%">
<img src='/images/Modularity_0D_1D_2D.png' align='center' width='500' height='400'/> 
<p style="text-align: center; font-size:10pt"><strong>fig. 3</strong> Modularity null models & space: In the null model of Newman’s
modularity (panel a) the average weight between nodes i and j is proportional to the product of their node degrees $(D_i · D_j)$. The topographic modularity’s null model (panels b & c) additionally includes a distance-dependent factor, $R_{ij}$, which is the average edge weight between all node pairs in the graph separated by the same distance that separates nodes i and j. Panel b illustrates $R_{ij}$ for a schematized 1D graph, shown with edges colored based on distance between the nodes they connect. Inset plot shows geometric factor in the topographic null model. Each term in $R^{(1D)}_{ij}$ is an off-diagonal sum in the adjacency matrix. Panel c shows the mask associated with a single geometric distance in a 2D image. Here R^{(2D)} at 1 pixel separation has aij complex structure in the Adjacency matrix for even the simple binary image shown in the inset. </p>
</p>

To assess the model's performance and compare it to other methods, we leverage the Berkeley Image Segmentation Data Set (BSDS), and develop a performance evaluation pipeline computing Precision, Recall and F-measure metrics between human annotations and boundaries discovered by the algorithm. 
<p align="center" width="100%">
<img src='/images/SegAssessPipeline.png' align='center' width='500' height='400'/> 
<p style="text-align: center; font-size:10pt"><strong>fig. 4</strong> Performance and benchmarking: Input image patch and associated human drawn ground truth boundaries (gT) provided by BSDS is displayed in the green box. The operations performed by model are displayed in the blue box. Other steps of model evaluation are illustrated in the remainder. (a) Filtering the raw image patch with a Gaussian kernel (σ = 1). (b) Phase relaxation in the network (Fig. 1b) produces a phase map. (c 1) Spatial gradient operation (δ/δr) and normalization resulting in probabilistic boundary map (pb ∈ [0, 1]). (d) Thresholding pb map at several values yielded binary boundary (bb) maps. (e) Match set was computed for each bb-gT pair at different distance tolerances, dt. (f) Precision, recall and F-measure were computed by ratios of boundary pixel sets. (c 2,3) To assess the performance of network models relative to baselines, we repeated steps (c) - (f) on Gaussian RF and image pixels independent sensors models, comparing F-measures by subtraction. </p>
</p>

The F-measure metric demonstrates the improvement in boundary detection provided by the 2D Topographic Modularity method (TM-2D) with Kuramoto relaxation over other methods.
<p align="center" width="100%">
<img src='/images/Fmax_img_seg.jpg' align='center' width='750' height='500'/>
<p style="text-align: center; font-size:10pt"><strong>fig. 5</strong> ∆F-measure model comparison: Violin plots show ∆FG distribution with moments of ∆Precision, ∆Recall and ∆F-measure distributions across 500 image patches in red, blue and green, respectively. ∆F relative to Gaussian RF Independent Sensors model. Optimal hyper-parameters(rM ,ks), statistical significance, p-values and distribution moments indicated above each method. Performance of ISO, TM-1D and TM-2D models relative to Gauss RF are statistically significant, as determined by Mann-Whitney U (aka rank-sum) test. </p>
</p>
