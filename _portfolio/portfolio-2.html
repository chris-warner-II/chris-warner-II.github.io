---
title: "2. Probabilistic binary latent variable model infers hidden structure in spike trains."
excerpt: "<img src='/images/CA_model.png' width='350' height='300'/> <img src='/images/CA_Robustness.png' width='550' height='400'/><br/> We introduce a novel, probabilistic binary latent variable (BLV) model to detect noisy or approximate repeats of patterns in sparse binary data. We adapt the framework of the 'Noisy-OR model', previously used to infer hidden diseases from observed symptoms, to neuron spiking mechanics and demonstrate the model's capability by extracting structure in recordings from retinal neurons. There, the task is to 'explain' spikes of individual neurons in terms of groups of neurons, 'Cell Assemblies' (CAs), that often fire together, due to mutual interactions or other causes. The conditional probability kernels of the latent components are learned from the data in an expectation maximization scheme, alternately performing inference of latent states and parameter adjustments to the model. We thoroughly validate the model on synthesized spike trains constructed to statistically resemble recorded retinal responses to white noise stimulus and natural movie stimulus in data. Finally, we apply our model to spiking responses recorded in retinal ganglion cells (RGCs) during stimulation with a movie and discuss the found structure."
collection: portfolio
---

<style>
  body {
    margin: 0;
  }

  figure {
    width: 31%; /* Adjusted to leave space for boundaries */
    margin: 0.5 0.5%; /* Added margin for space between figures */
    padding: 10px;
  }

  video,
  img {
    width: 100%;
    display: block;
  }
</style>


<p style="text-align: center; font-size:11pt"><strong>Expertise Demonstrated:</strong> Latent Variable Model, Bayesian probability, Expectation Maximization, Synthetic Data, Model Validation, Exploratory Data Analysis </p>

<header style="text-align: center">The Data</header>

<!--  Embed video of white noise stim and natural movie stim with PSTH and RFs. -->
<div style="display: flex; width: 100%;">

  <figure style="width: 31%;">
    <video controls width="100%" autoplay loop muted >
      <source src="/images/movie_wnrep.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <figcaption><strong>a)</strong>  White Noise Stimulus</figcaption>
  </figure>

  <figure style="width: 31%;">
    <img src="/images/CA_RFs.jpg" alt="Image" style="width: 100%;">
    <figcaption><strong>b)</strong> Receptive Fields of 55 RGC's</figcaption>
  </figure>

  <figure style="width: 31%;">
    <video controls width="100%" autoplay loop muted >
      <source src="/images/movie_catrep.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <figcaption><strong>c)</strong> Natural Movie Stimulus</figcaption>
  </figure>

</div> 

<p style="text-align: center; font-size:10pt"><strong>fig. 1</strong> Stimulus and Retinal Ganglion Cell Receptive Field Lattice </p>


White Noise stimulus, uncorrelated in space and time, is very different from Natural Movie stimulus and the retina responds very differently to the two types of input. Visual inspection of retinal responses to white noise stimulus vs. natural movie stimulus reveal clear spatial and temporal differences. The figure below shows peristimulus time histograms (PSTH) of a population of retinal ganglion cells (RGCs) responding to the two stimulus types. <a href="https://www.nature.com/articles/nature07140.pdf">Generalized Linear Models (GLMs)</a> of retina well capture the responses to white noise, but they fail to capture responses to natural movies, which contain spatial and temporal correlations in the stimulus and responses. Aside from the clear spatial correlations in responses to natural movies, it appears that single cell responses are also more variable (smeared out) in time trial-to-trial and that those temporal variations may be shared across clusters of cells.


  <figure style="width: 100%;">
    <img src="/images/CA_PSTHs.jpg" alt="Image" style="width: 100%;">
    <figcaption><strong>fig. 2</strong> Responses and Receptive Fields of Off-Brisk Transient Retinal Ganglion cells: Left Top, responses to white noise. Left Bottom, responses to natural movie. Color indicates #Trials in which cell (y-axis) spiked during a 1ms interval of stimulus presentation (x-axis). Right, receptive fields for 55 recorded RGCs. Geometric RF relationships in visual space maintained in cell ordering.</figcaption>
  </figure>

<header style="text-align: center">The Model</header>

To explore this phenomenon, we introduce the Binary Latent Variable (BLV) Model, which allows for two causes of a cell's observed firing $\mathbf{y}$, its individual intrinsic firing rate, $\mathbf{R}_i$, and its membership $\mathbf{P}_{ia}$ in an active Cell Assembly $\mathbf{z}$. The model schematic is displayed below.<br/>


<p align="center" width="100%">
  <img src='/images/CA_model.png' align='center' width='400' height='250'/> 
  <p style="text-align: center; font-size:10pt"><strong>fig. 3</strong> Schematic of BLV model applied to detect patterns in recordings of neural activity: In the model, individual spikes in a spike-word $\mathbf{y}$ can arise from two sources. First, each of the N cells has some probability of firing without any latent unit activity, expressed by N-vector $\mathbf{R}$. Second, a cell can fire because it is a member of a latent cell group, which is active. For the M latent variables, the membership structure between latent and observed variables is expressed by the MxN Matrix $\mathbf{P}$ of conditional probabilities. The scalar Q parameter sets a binomial prior on the activity in the sparse vector of latent variables, $\mathbf{z}$. </p>
</p>

 Assuming sparse activation and binomial distribution of latent states and conditional independence of observation vector given latent variables, the model yields the joint probability for a single observed unit's activity $y_i$ and latent vector $\mathbf{z}$ given by (see <a href="https://chris-warner-ii.github.io/publication/2022-paper-3">paper</a> for further model assumptions and full derivation):<br/><br/>

<p align="center" width="100%">
  $p(y_i,\mathbf{z}) = p(\mathbf{z}) p(y_i \vert \mathbf{z})$ <br/><br/>

  $p(y_i,\mathbf{z}) = p(\mathbf{z}) p(y_i=0 \vert \mathbf{z})^{(1-y_i)} p(y_i=1 \vert \mathbf{z})^{y_i}$ <br/><br/>

  $p(y_i,\mathbf{z}) = p(\mathbf{z}) p(y_i=0 \vert \mathbf{z})^{(1-y_i)} \bigg [ 1-p(y_i=0 \vert \mathbf{z}) \bigg ] ^{y_i}$ <br/><br/>

  $p(y_i,\mathbf{z}) = {M\choose |\mathbf{z}|} \cdot  Q^{|\mathbf{z}|}\cdot (1-Q)^{\big( M - |\mathbf{z}| \big)}   \bigg [ R_i^{ \big ( 1 - \frac{|\mathbf{z}|}{M} \big ) } \prod_{a=1}^M (P_{ia})^{z_a} \bigg ]^{(1-y_i)} \bigg [ 1 -  R_i^{ \big ( 1 - \frac{|\mathbf{z}|}{M} \big ) } \prod_{a=1}^M (P_{ia})^{z_a} \bigg ]^{y_i}$ <br/><br/>
</p>

We fit the BLV Model using an Expectation Maximization (EM) framework. For each observed spike-word $\mathbf{y}$, learning proceeds in two steps. First, the latent variables $\mathbf{z}$ are inferred with model parameters fixed. Then, model parameters are adjusted to maximize the derivative of the log joint probability of latent and observed states $p(\mathbf{y},\mathbf{z})$. with respect to each parameter. Derivatives are computed with respect to unconstrained parameters ($q, r, \rho$) and passed through a logistic parametrization, $P = \sigma(\rho)$, to enable the interpretation of constrained parameter values ($Q, R, P$) as probabilities $\in [0,1]$. Derivatives with respect to each model parameter are shown below: <br/><br/>

<p align="center" width="100%">
  $\frac{\partial \: log \: p(y_i,\mathbf{z})}{\partial q} = |\mathbf{z}| -  M \sigma(q)$ <br/><br/>

  $\frac{\partial \: log \: p(y_i,\mathbf{z})}{\partial r_i} = \bigg ( 1-\frac{|\mathbf{z}|}{M} \bigg ) \: \bigg (1-\sigma(r_i) \bigg ) \: \bigg [ (1-y_i) - \frac{y_i \:C_i}{(1-C_i)} \bigg ]$ <br/><br/>

  $\frac{\partial \: log \: p(y_i,\mathbf{z})}{\partial \rho_{ia}} = z_a \: \bigg (1-\sigma(\rho_{ia}) \bigg ) \: \bigg [ (1-y_i) - \frac{y_i \:C_i}{(1-C_i)} \bigg ]$ <br/><br/>
</p>

where $C_i := \sigma(r_i)^{\big ( 1-\frac{|\mathbf{z}|}{M} \big )} \prod_{a=1}^M \sigma(\rho_{ia})^{z_a}$ <br/><br/>

<header style="text-align: center">Model Validation</header>

Before applying the model to real retinal data, it is important to first validate the model using synthetic data to ensure that the model is able to learn known structure that has been embedded into the data. To that end, we constructed synthetic data that  matched certain moments measured in retinal spike train responses to white noise and natural movies, process described in figure 4 below. Interestingly, the difference between model parameters fit to the regimes yield an intuitive interpretation. The best-fit parameters reveal that, under the assumptions of the model, responses to natural movie stimulus contain fewer active cell assemblies in any observed spike-word, while each individual cell assembly contains more cells with stronger membership or participation in that assembly, when compared to responses of the same cell population responding to white noise stimulus.


<p align="center" width="100%">
  <img src='/images/CA_synthetic_data_moments.png' align='center' width='750' height='550'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 4</strong> Fitting synthetic model to recorded spike-word moments: Comparison of spike-word moments from retinal responses to white noise (Wnz) in green, and natural movie (Mov) in blue to synthetic data fitted to natural movie responses (Syn) in red. Recording data binned at 5ms. Top row from left to right shows probability density functions for spike-word length, |y|, average single-cell activity, ⟨yi⟩, and pairwise cell coactivity, ⟨yi · yj⟩. Bottom row shows quantile-quantile (QQ) plots - a pair of cumulative density function plotted against each other. See legend, left plot. QQ values measure average deviation from the unity line, larger values indicating bigger differences between distributions. </p>
</p>

Multiple models were trained on synthetic data and the structure discovered by each model was compared to what other models learned and to the ground truth. Figure 5 walks through the process of quantifying model match to other models and model match to ground truth. The cosine similarity measure, defined as the angle between two N-dimensional vectors in cell-assembly membership space, was used:  <br/><br/>

<p align="center" width="100%">
  $cs(v_1,v_2)= \frac{(v_1)^\top v_2}{\|v_1\| \|v_2\|}$  <br/><br/>
</p>

From the model validation procedure, we verified that when two models trained on structure resembling natural movie responses learned similar structure, that structure also existed in the ground truth model. This allows us to be reasonably confident that cell assembly structure that is learned robustly across multiple models in real neural data is meaningful.


<div style="display: flex; width: 100%;">

  <figure style="width: 49%;">
    <img src="/images/CA_synth_natMov1.png" alt="Image" style="width: 100%;">
    <figcaption><strong>a)</strong> Assessing similarity of cell assembly structure learned by different models trained on synthetic data fitted to natural movie responses. Left column shows M × M matrices of cosine similarity (cs) values between all cell assembly pairs across a model pair. Top, with arbitrary order and bottom, with cell assemblies matched across models based on pairwise cs. Right shows the pair of $\mathbf{P}$ matrices with columns, cell assemblies, aligned to maximize cs across all matched pairs. Blue bars in bottom right show cs for each matching column pair above. Note that blue bars are equivalent to diagonal elements in matched cs matrix in bottom left. The difference between diagonal means of the matched (bottom left) and the unmatched (top left) cs matrices, $\Delta cs$, provides a simple scalar measure of model similarity.</figcaption>
  </figure>

  <figure style="width: 49%;">
    <img src="/images/CA_synth_natMov2.png" alt="Image" style="width: 100%;">
    <figcaption><strong>b)</strong> Cross-validation of six models trained on synthetic data matched fitted to natural movie responses. Each element in matrix shows average $\Delta cs$ (relative to null without CA matching) between all matched CA pairs within a model pair. Note that for visual clarity using this color scheme, the unity diagonal elements have been set to zero. Vector labeled ’GT’ on right shows average $\Delta cs$ metric between model and ground truth model used to generate the data. Example described in left panel, comparison between Mod2 and Mod1B, hilighted with orange square. Each element of matrix contains a similar pairwise model comparison.</figcaption>
  </figure>

</div> 

<figure style="width: 100%;">
  <img src="/images/CA_synth_natMov3.png" alt="Image" style="width: 100%;">
  <figcaption><strong>fig. 5 c)</strong> Individual cross-validated CAs often match GT: Results for synthetic data fitted to natural movie responses. The left plot compares the cosine similarity (cs) between matched pairs of CAs in two learned models (Mod1 and Mod2) on the x-coordinate to cs between each model’s CA and matching CA in the GT on the y-coordinate. Each point represents similarities between one CA in a model (Mod1 in blue and Mod2 in green) and a matching CA in the GT. The points are connected by a faint grey vertical line if CAs in models are matched to different GT CAs. Red ’o’ highlights CA in model pair with smaller cs match to GT, and a black diamond marks points for which the two models are matched to the same CA in the GT (i.e., where green and blue points coincide). Larger blue and green ’+’ show $\mu$ and $\sigma$ of each model’s CA population. The right plot shows the distribution of distances in the left plot between points and the unity line. Pearson correlation coefficients (r) for three scatter groups in left plots are shown in legend on the right.</figcaption>
</figure>

<header style="text-align: center"><hr style="width:25%">Exploratory Data Analysis<hr style="width:25%"></header>

In order to more systematically and methodically quantify the type of structure found by our BLV model in neural data, we constructed four metrics.<br/>

<p style="text-align: left; font-size:11pt">
  <strong>(Q1).</strong>  How many cells participate in a CA? Are the CA’s membership boundaries crisp or diffuse? <br/>
  <strong>(M1). Membership Crispness ($C_M$)</strong>, based on a d′ metric, from Signal Detection Theory, quantifies how well member cells and nonmember cells are separated in the corresponding column $P_{.a}$ of the learned model parameters. The conditional activation probabilities of member and nonmember cells are modeled by normal distributions. $C_M$ is computed as: 
</p>

<p align="center" width="100%">
  $C_M = \frac{\mu_{in}-\mu_{out}}{\sqrt(\sigma_{in}^2+\sigma_{out}^2)} $  <br/><br/>
</p>

<p style="text-align: left; font-size:11pt">
  with $\mu_{in}$ and $\sigma_{in}$ the mean and standard deviation of P values of cells determined to be ”in” the CA, the remainder of cells being labeled as ”out”. Three illustrative examples of CAs with varying CM values are shown in figure 6.
</p>


<p align="center" width="100%">
  <img src='/images/CA_Crispness.png' align='center' width='750' height='150'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 6</strong> Membership Crispness $C_M$ example: Cell assembly $C_M$ values ranging from ”diffuse” (a) to ”crisp” (c). In each panel, numbered ovals represent the cells the receptive fields with the saturation of the red color indicating the degree of CA membership, legend above dashed line. Corresponding column $P_{·a}$ of fitted model parameters shown on the right.</p>
</p>

<p style="text-align: left; font-size:11pt">
  <strong>(Q2).</strong>  Are individual CAs found robustly across models, with similar spatial membership structure and similar temporal response profiles? <br/>
  <strong>(M2). Cross-validation Robustness ($R_X$)</strong> quantifies how repeatable membership structure and temporal activation of cell assemblies is when learned across training multiple BLV models with the same prior setting on different sub-samplings and cross-validation splits of the same data. Illustrated in figure 7, for a single CA, average membership cosine similarity ($cs_M$) with the matching CA in other models and average temporal similarities ($cs_{\tau}$) by computing cosine similarity of rows in panel b and columns of panel f. Observing that membership and temporal ⟨cs⟩ across models are highly correlated (c), we combine them into a single Robustness measure, yeilding: 
</p>

<p align="center" width="100%">
  $R_X = \sqrt{( \langle cs_{\tau} \rangle _X . \langle cs_{M} \rangle _X )}$  <br/><br/>
</p>

<p style="text-align:left; font-size:11pt">
  where $\langle cs \rangle _X$ indicates similarity to matching CAs, either membership or temporal, averaged across pairs of fitted BLV models. $R_X$ is bounded between 0 and 1, obtaining large values only when temporal and membership similarity across matching CAs in multiple models are both high.
</p>


<p align="center" width="100%">
  <img src='/images/CA_Robustness.png' align='center' width='750' height='350'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 7</strong> Cross-validation Robustness $R_X$ example: (a). Top two panels show raster plots time vs. trial for activity in latent variable for CA z50 (red) and in observed variables (spikes) for the member cells of z50, y7 (green), y10 (blue), y31 (black), and y35 (cyan). (b). PSTHs of activity of the CA corresponding to z50 above inferred by six cross-validated models, each normalized with total number of activations of this CA (white numbers on right). Different models are arranged on the y-axis, PSTH from CA z50 shown above is the top line, PSTHs from CAs in other models, matched to z50, shown in other rows. (c). Membership cosine similarity ($cs_M$) vs. temporal cosine similarity ($cs_{\tau}$) for each CA in model with matching CAs, averaged across 5 matching CAs in 5 cross-validation models. (d). Cross-validation Robustness ($R_X$) vs. Membership Crispness ($C_M$) metrics for all CAs in one model. CA z50 highlighted with red ”50” in panels c & d. (e). Cell RFs. Saturation level of red color indicates CA membership strength, $P_{·a}$ value, and outline colors match raster colors in panel a. (f). Matching columns of $\mathbf{P}$ matrices of different models for CA z50, with z50 in the leftmost column and matching CAs of the other cross-validation models in other columns, labels (model, CA id) as in (b).</p>
</p>

<p style="text-align:left; font-size:11pt">
  <strong>(Q3).</strong>  In models trained on multiple cell-types, do CAs cross cell-type boundaries? <br/>
  <strong>(M3). Cell-type Heterogeneity ($H$)</strong>, is a measure of how mixed the membership of a cell assembly is across a pair of cell-types. We define heterogeneity as:
</p>

<p align="center" width="100%">
  $H = \frac{min(\#_{ct1},\#_{ct2})}{avg(\#_{ct1},\#_{ct2})}$<br/><br/>
</p>


<p style="text-align: left; font-size:11pt">
  where $\#_{cti}$ is the number of cells of type i participating in the CA. H is bounded between 0 and 1, requiring mixed CA participation to be nonzero, and taking a maximum value of 1 when each cell type contributes half of the cells to the CA. A sample of a cell assembly involving offBT and offBS cells with high heterogeneity value is shown in Fig 8. 
</p>

<p align="center" width="100%">
  <img src='/images/CA_Hetero.png' align='center' width='750' height='150'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 8</strong> Cell-type Heterogeneity H example: Single CA comprised of offBT (red, left) and onBT (blue, right) cell types. Ovals indicate cell RFs and color intensity indicates membership strength, i.e., $P_{·a}$ value. Legend above dashed line.</p>
</p>


<p style="text-align:left; font-size:11pt">
  <strong>(Q4).</strong>  Are spike-words observed during CA activity significantly different from what the GLM retinal model would predict for the same stimulus?<br/>
  <strong>(M4). Cell-type Heterogeneity ($H$)</strong>, is a measure of how mixed the membership of a cell assembly is across a pair of cell-types. We define heterogeneity as:
</p>




<header style="text-align: center"><hr style="width:25%">Results in Retina<hr style="width:25%"></header>

Results on real retina data using EDA paradigm. Have 8 figures. Use all, or just some?

We now apply the BLV model directly to spike train data collected from in vitro rat retinal ganglion cells (RGCs). Activity from 329 cells of 11 different cell types was recorded using a multielectrode array by the lab of Greg Field. We use data from 55 Off-Brisk Transient (offBT), 39 Off-Brisk Sustained (offBS) and 43 On-Brisk Transient (onBT) cells. The remaining 8 cell-types did not have data from a sufficient number of cells for our analysis. Cell receptive fields (RFs) were fit using responses to 1 hour presentation of white noise stimulus. The data we analyze consists of RGC spike-train responses to 200 trial repeats of 5 second clips of white noise and natural movie stimulus. Natural movie stimulus from the ”Cat Cam” data set 

We trained models on between 500k and 1M spike words extracted from raw spike trains binned at 5ms


<p align="center" width="100%">
  <img src='/images/CA_Robustness.png' align='center' width='750' height='550'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 7</strong> Image Caption Here. </p>
</p>





Find the full publication <a href="https://chris-warner-ii.github.io/publication/2022-paper-3">here</a>,

and the code repo <a href="https://github.com/chris-warner-II/Cell_Assembly_Codebase">here</a>.


