---
title: "2. Probabilistic binary latent variable model infers hidden structure in spike trains."
excerpt: "<img src='/images/CA_model.png' width='350' height='300'/> <img src='/images/CA_Robustness.png' width='550' height='400'/><br/> We introduce a novel, probabilistic binary latent variable (BLV) model to detect noisy or approximate repeats of patterns in sparse binary data. We adapt the framework of the 'Noisy-OR model', previously used to infer hidden diseases from observed symptoms, to neuron spiking mechanics and demonstrate the model's capability by extracting structure in recordings from retinal neurons. There, the task is to 'explain' spikes of individual neurons in terms of groups of neurons, 'Cell Assemblies' (CAs), that often fire together, due to mutual interactions or other causes. The conditional probability kernels of the latent components are learned from the data in an expectation maximization scheme, alternately performing inference of latent states and parameter adjustments to the model. We thoroughly validate the model on synthesized spike trains constructed to statistically resemble recorded retinal responses to white noise stimulus and natural movie stimulus in data. Finally, we apply our model to spiking responses recorded in retinal ganglion cells (RGCs) during stimulation with a movie and discuss the found structure."
collection: portfolio
---

<style>
  body {
    margin: 0;
  }

  figure {
    width: 31%; /* Adjusted to leave space for boundaries */
    margin: 0.5 0.5%; /* Added margin for space between figures */
    padding: 10px;
  }

  video,
  img {
    width: 100%;
    display: block;
  }
</style>


 <p style="text-align: center; font-size:11pt"><strong>Expertise Demonstrated:</strong> Latent Variable Model, Bayesian probability, Expectation Maximization, Synthetic Data, Model Validation, Exploratory Data Analysis </p>


White Noise stimulus (ie., "TV snow"), uncorrelated in space and time, is very different from Natural Movie stimulus and the retina responds very differently to the two types of input. Visual inspection of retinal responses to white noise stimulus vs. natural movie stimulus reveal clear spatial and temporal differences. The figure below shows peristimulus time histograms (PSTH) of a population of retinal ganglion cells (RGCs) responding to the two stimulus types. <a href="https://www.nature.com/articles/nature07140.pdf">Generalized Linear Models (GLMs)</a> of retina well capture the responses to white noise, but they fail to capture responses to natural movies, which contain spatial and temporal correlations in the stimulus and responses. Aside from the clear spatial correlations in responses to natural movies, it appears that single cell responses are also more variable (smeared out) in time trial-to-trial and that those temporal variations may be shared across clusters of cells.



  <!--  Embed video of white noise stim and natural movie stim with PSTH and RFs. -->
  <div style="display: flex; width: 100%;">

    <figure style="width: 31%;">
      <video controls width="100%" autoplay loop muted >
        <source src="/images/movie_wnrep.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <figcaption>White Noise Stimulus</figcaption>
    </figure>

    <figure style="width: 31%;">
      <img src="/images/CA_RFs.jpg" alt="Image" style="width: 100%;">
      <figcaption>Receptive Fields of 55 RGC's</figcaption>
    </figure>

    <figure style="width: 31%;">
      <video controls width="100%" autoplay loop muted >
        <source src="/images/movie_catrep.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <figcaption>Natural Movie Stimulus</figcaption>
    </figure>

  </div>

  <figure style="width: 100%;">
    <img src="/images/CA_PSTHs.jpg" alt="Image" style="width: 100%;">
    <figcaption><strong>fig. 1</strong> Responses and Receptive Fields of Off-Brisk Transient Retinal Ganglion cells: Left Top, responses to white noise. Left Bottom, responses to natural movie. Color indicates #Trials in which cell (y-axis) spiked during a 1ms interval of stimulus presentation (x-axis). Right, receptive fields for 55 recorded RGCs. Geometric RF relationships in visual space maintained in cell ordering.</figcaption>
  </figure>


To explore this phenomenon, we introduce the Binary Latent Variable (BLV) Model, which allows for two causes for a cell's observed firing, its individual intrinsic firing rate, $\mathbf{R}_i$, and its membership in a Cell Assembly, $\mathbf{P}_{ia}$. We assume sparse activation and binomial distribution of latent states $\mathbf{z}$ and conditional independence of observation vector $\mathbf{y}$ given latent variables $\mathbf{z}$. <br/>


<p align="center" width="100%">
  <img src='/images/CA_model.png' align='center' width='400' height='300'/> 
  <p style="text-align: center; font-size:10pt"><strong>fig. 2</strong> Schematic of BLV model applied to detect patterns in recordings of neural activity: In the model, individual spikes in a spike-word $\mathbf{y}$ can arise from two sources. First, each of the N cells has some probability of firing without any latent unit activity, expressed by N-vector $\mathbf{R}$. Second, a cell can fire because it is a member of a latent cell group, which is active. For the M latent variables, the membership structure between latent and observed variables is expressed by the MxN Matrix $\mathbf{P}$ of conditional probabilities. The scalar Q parameter sets a binomial prior on the activity in the sparse vector of latent variables, $\mathbf{z}$. </p>
</p>

This yields the joint probability for a single observed unit's activity $y_i$ and latent vector $\mathbf{z}$ given by (see <a href="https://chris-warner-ii.github.io/publication/2022-paper-3">paper</a> for thorough derivation):<br/><br/>

$p(y_i,\mathbf{z}) = p(\mathbf{z}) p(y_i \vert \mathbf{z})$ <br/><br/>

$p(y_i,\mathbf{z}) = p(\mathbf{z}) p(y_i=0 \vert \mathbf{z})^{(1-y_i)} p(y_i=1 \vert \mathbf{z})^{y_i}$ <br/><br/>

$p(y_i,\mathbf{z}) = p(\mathbf{z}) p(y_i=0 \vert \mathbf{z})^{(1-y_i)} \bigg [ 1-p(y_i=0 \vert \mathbf{z}) \bigg ] ^{y_i}$ <br/><br/>

$p(y_i,\mathbf{z}) = {M\choose |\mathbf{z}|} \cdot  Q^{|\mathbf{z}|}\cdot (1-Q)^{\big( M - |\mathbf{z}| \big)}   \bigg [ R_i^{ \big ( 1 - \frac{|\mathbf{z}|}{M} \big ) } \prod_{a=1}^M (P_{ia})^{z_a} \bigg ]^{(1-y_i)} \bigg [ 1 -  R_i^{ \big ( 1 - \frac{|\mathbf{z}|}{M} \big ) } \prod_{a=1}^M (P_{ia})^{z_a} \bigg ]^{y_i}$ <br/><br/>

Once the BLV model is derived, we fit it to data using an Expectation Maximization (EM) framework. For each observed spike-word $\mathbf{y}$, learning proceeds in two steps. First, the latent variables $\mathbf{z}$ are inferred with the current fixed model parameters. Then, model parameters are adjusted to maximize the derivative of the log joint probability of latent and observed states $p(\mathbf{y},\mathbf{z})$. with respect to each parameter. Derivatives are computed with respect to unconstrained variables ($q, r, \rho$) passed through a logistic parametrization to force outputs toward binary values. Derivatives with respect to each model parameter are shown below. <br/><br/>


$\frac{\partial \: log \: p(y_i,\mathbf{z})}{\partial q} = |\mathbf{z}| -  M \sigma(q)$ <br/><br/>

$\frac{\partial \: log \: p(y_i,\mathbf{z})}{\partial r_i} = \bigg ( 1-\frac{|\mathbf{z}|}{M} \bigg ) \: \bigg (1-\sigma(r_i) \bigg ) \: \bigg [ (1-y_i) - \frac{y_i \:C_i}{(1-C_i)} \bigg ]$ <br/><br/>

$\frac{\partial \: log \: p(y_i,\mathbf{z})}{\partial \rho_{ia}} = z_a \: \bigg (1-\sigma(\rho_{ia}) \bigg ) \: \bigg [ (1-y_i) - \frac{y_i \:C_i}{(1-C_i)} \bigg ]$ <br/><br/>

where <br/><br/>

$\quad C_i := \sigma(r_i)^{\big ( 1-\frac{|\mathbf{z}|}{M} \big )} \prod_{a=1}^M \sigma(\rho_{ia})^{z_a}$ <br/><br/>








Making synthetic data with moments fit to recorded retina data. Different model parameters when fit to white noise vs natural movies. Maybe just use table, no figure? Since we have 4 figures below.


<p align="center" width="100%">
  <img src='/images/CA_synthetic_data_moments.png' align='center' width='750' height='550'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 3</strong> Fitting synthetic model to recorded spike-word moments: Comparison of spike-word moments from retinal responses to white noise (Wnz) in green, and natural movie (Mov) in blue to synthetic data fitted to natural movie responses (Syn) in red. Recording data binned at 5ms. Top row from left to right shows probability density functions for spike-word length, |y|, average single-cell activity, ⟨yi⟩, and pairwise cell coactivity, ⟨yi · yj⟩. Bottom row shows quantile-quantile (QQ) plots - a pair of cumulative density function plotted against each other. See legend, left plot. QQ values measure average deviation from the unity line, larger values indicating bigger differences between distributions. </p>
</p>



Validating synthetic model using ground truth. Don't need metrics explained here yet. Have 4 figures.

<p align="center" width="100%">
  <img src='/images/image-alignment-150x150.jpg' align='center' width='750' height='550'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 4</strong> Image Caption Here. </p>




Exploratory Data Analysis and metrics used to make statements about data

<p align="center" width="100%">
  <img src='/images/image-alignment-150x150.jpg' align='center' width='750' height='550'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 5</strong> Image Caption Here. </p>
</p>





Results on real retina data using EDA paradigm. Have 8 figures. Use all, or just some?



<p align="center" width="100%">
  <img src='/images/CA_Robustness.png' align='center' width='750' height='550'/>
  <p style="text-align: center; font-size:10pt"><strong>fig. 6</strong> Image Caption Here. </p>
</p>





Find the full publication <a href="https://chris-warner-ii.github.io/publication/2022-paper-3">here</a>,

and the code repo <a href="https://github.com/chris-warner-II/Cell_Assembly_Codebase">here</a>.


