---
title: "3. Protein-Drug Interaction Prediction using Machine Learning"
excerpt: "<img src='/images/CODA_Airflow_Dags_flowchart.pdf' width='550' height='400'><img src='/images/CODA_ec50_ligand_and_ach2.png' width='550' height='400'><br/> As a Machine Learning consultant for CODA Biotherapeutics, I contributed to an algorithm that guides development of a chemogenetic platform designed to modulate neuronal activity to therapeutic effect. The model predicts the fitness of novel synthetic ligand-gated ion channels that were engineered to be highly responsive to a specific small molecules but are otherwise inactive. Models were trained on proteins that had been synthesized and measured in the lab, a slow and expensive process. We used machine learning prediction on novel protein-ligand combinations to decrease the time and cost of this discovery process. We developed and deployed the pipeline to (1). embed protein and ligand information as inputs, (2). encode laboratory measurements as outputs, (3). train models including hyperparameter tuning, and (4). simulate novel receptors - making predictions on them and evaluating fitness of those based on model predictions."
collection: portfolio
---

<p style="text-align: center; font-size:11pt"><strong>Skills & Expertise:</strong> AWS Cloud Computing, </p>


<br/><header style="text-align: center">The Company & Mission</header><br/>

CODA Biotherapeutics develops a chemogenetic platform designed to modulate neuronal activity. With chemogenetics, target neuronal populations are modified using gene therapy to express a tunable ligand-gated ion channel. These ligand-gated ion channels are engineered to be highly responsive to a specific proprietary small molecule but are otherwise inactive. The interaction of the small molecule and engineered receptor allows for exquisite, dose-dependent control of the neurons to generate the therapeutic effect.

<br/><header style="text-align: center">Goal of ML team</header><br/>

The goal of this project is to predict functional properties of unobserved receptor mutants from measured properties of synthesized receptors and to make recommendations to biology team for fruitful directions for future receptor synthesis.

<br/><header style="text-align: center">Data Embedding</header><br/>

  <figure style="width: 100%;">
    <img src="/images/CODA_ec50_posteriors.png" alt="Image" style="width: 70%;">
    <figcaption><strong>fig. 1</strong> EC50 posterior estimation examples for 4 receptor-ligand (RL) pairs. Each row represents an RL-pair. In each row, left panel: Blue dots show plate-reader input data points, ligand concentration vs. observed fluorescence measurements. By bootstrapping, multiple logistic curves can be fit to subsampling of data points, black lines. From each logistic curve, EC50 is concentration level (x-axis) at which curve predicts 50% quench. Right panels show probability density function of EC50 values across bootstrapping iterations.</figcaption>
  </figure>

Using a set of biological assays, a dataset is collected consisting of a specific ligand-gated ion channel (protein), a particular ligand at a known concentration (drug) and the fluorescence inside of a cell indicating how sensitive the protein was to the drug at the given concentration. We use subsets of that data to compute logistic functions of fluorescence vs concentration and can find a distribution of "half-maximal effective concentration" (EC50) values. Samples from the EC50 distribution become the output  of our model. 

The model's input consists of embedding representations of the drug molecular features and protein amino acid (AA) sequence. With the protein, we try to leverage transfer learning by using embeddings that were trained on large databases of proteins such as Prottrans and Protvec. We also supplement the protein embedding representation with physiochemical signatures of particular AA residues of interest. Drug / ligand embeddings are constructed from extended connectivity fingerprints which determine whether common molecular domains are present or absent.

<br/><header style="text-align: center">Model Training</header><br/>

We built and trained a Multi-Layer Perceptron (MLP) model using 85% of the data for training and 15% for validation. We trained single models sweeping over hyperparameter values and choosing the pair that minimized the validation loss between model predicted EC50 and value extracted from EC50 posterior distribution constructed from lab measurements. For this process we used a Bayesian sweep over model hyperparameters from <a href="https://wandb.ai/site">Weights and Biases</a>. Once settled upon hyperparameter values, we fixed them and trained an ensemble model to make a distribution of predictions for EC50 value for a particular protein-ligand pair. 

<br/><header style="text-align: center">Evaluation & Model Comparison</header><br/>

<br/><header style="text-align: center">Implementation & Deployment</header><br/>

<br/><header style="text-align: center">Summary</header><br/>

In this project, the big take-aways are:
  <ol>
    <li>one</li>
    <li>one</li>
    <li>one</li>
    <li>one</li>
    <li>one</li>
    <li>one</li>
    <li>one</li>
  </ol>
